{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=7\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import ctypes\n",
    "libgcc_s = ctypes.CDLL('libgcc_s.so.1')\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('/home/avic/OOD_Orientation_Generalization')\n",
    "from my_dataclasses import *\n",
    "from train.dataset import *\n",
    "from train.train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avic/om5/anaconda3/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/home/avic/om5/anaconda3/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 250/250 [11:13<00:00,  2.69s/it]\n",
      "100%|██████████| 250/250 [09:18<00:00,  2.23s/it]\n",
      "100%|██████████| 250/250 [07:27<00:00,  1.79s/it]\n",
      "100%|██████████| 250/250 [07:22<00:00,  1.77s/it]\n"
     ]
    }
   ],
   "source": [
    "for x in range(4):\n",
    "    e = ExpData.get_experiments(x)\n",
    "\n",
    "    batch_size = 1000\n",
    "    rd = RotationDataset(e)\n",
    "    # df = pd.read_csv(rd.training.full.path.merged_annotation_path())\n",
    "    # dataset = rd._Dataset(rd, df)\n",
    "    d = rd._Dataset(rd, rd.training.full.ann)\n",
    "    dataloader = DataLoader(d, batch_size, num_workers=8, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    model = models.resnet18(pretrained=False, num_classes=50)\n",
    "    model.load_state_dict(torch.load(e.checkpoint))\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    image_activations = np.zeros((len(dataloader) * batch_size, 512))\n",
    "\n",
    "    global avgpool_output\n",
    "    def hook(model, input, output):\n",
    "        global avgpool_output\n",
    "        avgpool_output = torch.squeeze(output).cpu().detach().numpy()\n",
    "\n",
    "    model.avgpool.register_forward_hook(hook)\n",
    "\n",
    "    pred_cat = np.zeros((len(dataloader), batch_size), dtype=int)\n",
    "    correct = np.zeros(pred_cat.shape, dtype=bool)\n",
    "\n",
    "    for b, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        images, targets = map(lambda t: t.to(device='cuda', non_blocking=True), batch)\n",
    "        with torch.no_grad():\n",
    "            preds = model(images)\n",
    "\n",
    "        preds_max = preds.argmax(dim=1)\n",
    "        pred_cat[b] = preds_max.cpu()\n",
    "        correct[b] = (preds_max == targets.flatten()).cpu()\n",
    "        image_activations[batch_size * b : batch_size * (b + 1)] = avgpool_output\n",
    "    \n",
    "    np.save(e.image_activations, image_activations)\n",
    "    np.save(os.path.join(e.eval_dir, f'pred_cat_{e.data_div}.npy'), pred_cat.flatten())\n",
    "    np.save(os.path.join(e.eval_dir, f'correct_{e.data_div}.npy'), correct.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [11:48<00:00,  2.83s/it]\n"
     ]
    }
   ],
   "source": [
    "for x in range(3, 4):\n",
    "    e = ExpData.get_experiments(x)\n",
    "\n",
    "    batch_size = 1000\n",
    "    rd = RotationDataset(e)\n",
    "    df = pd.read_csv(rd.testing.full.path.merged_annotation_path())\n",
    "    dataset = rd._Dataset(rd, df)\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size, num_workers=8, shuffle=False, pin_memory=True)\n",
    "    checkpoint = torch.load(e.checkpoint)\n",
    "    model = models.resnet18(pretrained=False, num_classes=50)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.cuda()\n",
    "    pass\n",
    "\n",
    "    assert len(dataset) % batch_size == 0\n",
    "    image_activations = np.zeros((len(dataloader) * batch_size, 512))\n",
    "\n",
    "    w = model.fc.weight.cpu().detach().numpy()\n",
    "    \n",
    "    image_activations = np.zeros((len(dataloader) * batch_size, 512))\n",
    "\n",
    "    global avgpool_output\n",
    "    def hook(model, input, output):\n",
    "        global avgpool_output\n",
    "        avgpool_output = torch.squeeze(output).cpu().detach().numpy()\n",
    "\n",
    "    model.avgpool.register_forward_hook(hook)\n",
    "    model.eval()\n",
    "    for b, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        images, targets = map(lambda t: t.to(device='cuda', non_blocking=True), batch)\n",
    "        with torch.no_grad():\n",
    "            preds = model(images)\n",
    "        image_activations[batch_size * b : batch_size * (b + 1)] = avgpool_output\n",
    "    np.save(e.image_activations, image_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_activations = np.load(e.image_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_heatmap_cell_ranges(num_cubelets):\n",
    "\n",
    "    assert num_cubelets % 2 == 0\n",
    "    \n",
    "    longtitude = num_cubelets + 1\n",
    "    latitude = num_cubelets // 2\n",
    "    r = 1\n",
    "\n",
    "    dim0, delta_theta = np.linspace(-np.pi, np.pi, longtitude, retstep=True)\n",
    "    delta_S = delta_theta / latitude\n",
    "\n",
    "    dim1 = 1-np.arange(2*latitude+1) * delta_S / (r**2 * delta_theta)\n",
    "    dim1 =  np.arccos(dim1)\n",
    "    dim1 = (dim1 - (np.pi / 2))\n",
    "\n",
    "    dim2 = np.linspace(-np.pi, np.pi, num_cubelets + 1)\n",
    "\n",
    "    \n",
    "    return dim0, dim1, dim2\n",
    "\n",
    "def div_heatmap(df, activations, num_cubelets=20):\n",
    "    dim0s, dim1s, dim2s = get_heatmap_cell_ranges(num_cubelets)\n",
    "\n",
    "    df['object_x_cat'] = pd.cut(df.object_x, dim0s).cat.codes\n",
    "    df['object_y_cat'] = pd.cut(df.object_y, dim1s).cat.codes\n",
    "    df['object_z_cat'] = pd.cut(df.object_z, dim2s).cat.codes\n",
    "    df['model_cats'] = pd.Categorical(df.model_name, categories=df.model_name.unique(), ordered=True).codes\n",
    "\n",
    "    groups = df.groupby([df.model_cats, df.object_x_cat, df.object_y_cat, df.object_z_cat])\n",
    "    groups_count = groups.ngroups\n",
    "    \n",
    "    activations_heatmap = np.zeros((512, 50, num_cubelets, num_cubelets, num_cubelets), dtype=np.float32)\n",
    "    for i, group in tqdm(enumerate(groups), total=groups_count):\n",
    "        m, x, y, z = group[0][0], group[0][1], group[0][2], group[0][3]\n",
    "        activations_heatmap[:, m, x, y, z] = np.mean(activations[group[1].index.tolist()], axis=0)\n",
    "\n",
    "    return activations_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "get_heatmap_cell_ranges(20)[0][[9, 11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "activations_heatmap = div_heatmap(dataset.frame, image_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.save(e.activations_heatmap, activations_heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "activations_heatmap = np.load(e.activations_heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "_, axes = plt.subplots(5, 10, figsize=(30, 15))\n",
    "for x in range(5):\n",
    "    for y in range(10):\n",
    "        axes[x][y].imshow(np.mean(activations_heatmaps[(x * 10) + y, 6], axis=2))\n",
    "        axes[x][y].set_xticks([])\n",
    "        axes[x][y].set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "_, axes = plt.subplots(5, 10, figsize=(30, 30))\n",
    "for x in range(5):\n",
    "    for y in range(10):\n",
    "        axes[x][y].imshow(np.mean(activations_heatmaps[(x * 10) + y, 0], axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
